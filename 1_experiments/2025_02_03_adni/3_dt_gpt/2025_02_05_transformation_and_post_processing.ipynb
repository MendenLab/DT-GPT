{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.02.2025 - Transformation & Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pandas.tseries.offsets import MonthBegin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_predictions_path = \".../predictions_raw.csv\"\n",
    "generated_predictions = pd.read_csv(generated_predictions_path)\n",
    "\n",
    "# Get true predictions\n",
    "true_predictions = pd.read_csv(\".../ADNI_short_test_ground_truth.csv\")\n",
    "\n",
    "# Target cols\n",
    "target_cols =  [\"CDRSB\", \"ADAS11\", \"MMSE\"]\n",
    "true_predictions = true_predictions[[\"PATIENT_ID\", \"MONTH\"] + target_cols]\n",
    "true_predictions = true_predictions.sort_values(by=[\"PATIENT_ID\", \"MONTH\"])\n",
    "\n",
    "# Mapping used throughout\n",
    "mapping = {\n",
    "    \"CDR-SB score\": \"CDRSB\",\n",
    "    \"ADAS11 score\": \"ADAS11\",\n",
    "    \"MMSE score\": \"MMSE\"\n",
    "}\n",
    "reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First do post-processing of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: sometimes the model repeats itself, so split anything after the first occurence of <patient_prediction> and keep only first part\n",
    "processed_predictions = generated_predictions.copy()\n",
    "processed_predictions[\"responses\"] = processed_predictions[\"responses\"].apply(lambda x: x.split(\"<patient_prediction>\")[0])\n",
    "\n",
    "#: apply stripping of whitespaces\n",
    "processed_predictions[\"responses\"] = processed_predictions[\"responses\"].apply(lambda x: x.strip())\n",
    "\n",
    "#: sometimes model makes 2 \"]}\" at the end instead of one -> in those cases keep only 1\n",
    "processed_predictions[\"responses\"] = processed_predictions[\"responses\"].apply(lambda x: x.split(\"]}\")[0] + \"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_predictions.iloc[10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of processed predictions: \", len(processed_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process into dataframes, then average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dfs = []\n",
    "\n",
    "# Iterate through each row in the processed_predictions dataframe\n",
    "for idx, row in tqdm(processed_predictions.iterrows()):\n",
    "    patient_id = row[\"patientid\"]\n",
    "    \n",
    "    try:\n",
    "        # Parse the JSON string into a dictionary\n",
    "        responses = json.loads(row[\"responses\"])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON for patient {patient_id} at index {idx}. Skipping.\")\n",
    "        continue  # Skip to the next iteration if JSON is invalid\n",
    "\n",
    "    # Extract the true predictions for the current patient\n",
    "    true_df = true_predictions[true_predictions[\"PATIENT_ID\"] == patient_id]\n",
    "\n",
    "    # Initialize a dataframe for the generated data with PATIENT_ID and MONTH\n",
    "    generated_patient_df = pd.DataFrame({\n",
    "        \"PATIENT_ID\": patient_id,\n",
    "        \"MONTH\": true_df[\"MONTH\"]\n",
    "    })\n",
    "\n",
    "    # Iterate through each target column to align generated values\n",
    "    for target_col in target_cols:\n",
    "        # Retrieve the generated values for the current target column\n",
    "        generated_values = responses.get(reverse_mapping[target_col], [])\n",
    "\n",
    "        # Identify the months where the true data for this target is not missing\n",
    "        non_na_true = true_df[[\"PATIENT_ID\", \"MONTH\", target_col]].dropna(subset=[target_col]).sort_values(by=\"MONTH\").reset_index(drop=True)\n",
    "\n",
    "        # Check if the number of generated values matches the number of non-missing entries\n",
    "        if len(generated_values) != len(non_na_true):\n",
    "            # If generated too much, cut the excess\n",
    "            if len(generated_values) > len(non_na_true):\n",
    "                print(f\"Generated too many values for '{target_col}' in patient '{patient_id}': \"\n",
    "                      f\"expected {len(non_na_true)}, got {len(generated_values)}. Cutting the excess.\")\n",
    "                generated_values = generated_values[:len(non_na_true)]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Length mismatch for '{target_col}' in patient '{patient_id}': \"\n",
    "                    f\"expected {len(non_na_true)}, got {len(generated_values)}.\"\n",
    "                )\n",
    "\n",
    "        # Initialize the target column with NaNs\n",
    "        generated_patient_df[target_col] = np.nan\n",
    "\n",
    "        # Assign the generated values to the corresponding months\n",
    "        generated_patient_df.loc[\n",
    "            generated_patient_df[\"MONTH\"].isin(non_na_true[\"MONTH\"]),\n",
    "            target_col\n",
    "        ] = generated_values\n",
    "\n",
    "    # Append the generated dataframe for the current patient to the list\n",
    "    generated_dfs.append(generated_patient_df)\n",
    "\n",
    "# Concatenate all generated dataframes into a single dataframe\n",
    "generated_df = pd.concat(generated_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the generated dataframe\n",
    "print(generated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now average by patient and month\n",
    "generated_df_averaged = generated_df.groupby([\"PATIENT_ID\", \"MONTH\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that average is correct for first patient\n",
    "patient_id_0 = generated_df_averaged[\"PATIENT_ID\"].iloc[0]\n",
    "original_df = generated_df[generated_df[\"PATIENT_ID\"] == patient_id_0]\n",
    "original_df_first_time = original_df[original_df[\"MONTH\"] == original_df[\"MONTH\"].min()]\n",
    "\n",
    "assert generated_df_averaged[generated_df_averaged[\"PATIENT_ID\"] == patient_id_0][\"CDRSB\"].iloc[0] == original_df_first_time[\"CDRSB\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with MAE with true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for consistency\n",
    "generated_df_averaged = generated_df_averaged.rename(columns=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with true predictions\n",
    "merged_df = pd.merge(generated_df_averaged, true_predictions, on=[\"PATIENT_ID\", \"MONTH\"], suffixes=(\"_generated\", \"_true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MAE by column\n",
    "mae = {}\n",
    "for col in target_cols:\n",
    "    mae[col] = np.abs(merged_df[col + \"_generated\"] - merged_df[col + \"_true\"]).mean()\n",
    "\n",
    "print(\"========== RESULTS ==========\")\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from statistics file\n",
    "std_CDRSB = 1.8347716172641326\n",
    "mean_CDSSB = 1.7012566427720828\n",
    "std_ADAS11 = 6.62023532076858\n",
    "mean_ADAS11 = 10.571872441365645\n",
    "std_MMSE = 2.9418718345388455\n",
    "mean_MMSE = 27.095790481554758\n",
    "\n",
    "# Normalize\n",
    "mae_normalized = {}\n",
    "mae_normalized[\"CDRSB\"] = mae[\"CDRSB\"] / std_CDRSB\n",
    "mae_normalized[\"ADAS11\"] = mae[\"ADAS11\"] / std_ADAS11\n",
    "mae_normalized[\"MMSE\"] = mae[\"MMSE\"] / std_MMSE\n",
    "\n",
    "print(\"========== NORMALIZED RESULTS ==========\")\n",
    "print(mae_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Copy Forward & LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_forward_predictions = pd.read_csv(\".../TEST_prediction_dataframe.csv\")\n",
    "copy_forward_targets = pd.read_csv(\".../TEST_target_dataframe.csv\")\n",
    "\n",
    "\n",
    "lightgbm_predictions = pd.read_csv(\".../TEST_prediction_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process generated predictions into same format as copy forward\n",
    "generated_df_averaged_no_na = generated_df_averaged.dropna(subset=target_cols, how=\"all\").copy()\n",
    "start_date = pd.to_datetime('2020-01-01')\n",
    "generated_df_averaged_no_na[\"date\"] = start_date + generated_df_averaged_no_na[\"MONTH\"]  * MonthBegin(1)\n",
    "generated_df_averaged_no_na = generated_df_averaged_no_na.rename(columns={\"PATIENT_ID\": \"patientid\"})\n",
    "generated_df_averaged_no_na = generated_df_averaged_no_na.drop(columns=[\"MONTH\"])\n",
    "generated_df_averaged_no_na = generated_df_averaged_no_na[[\"patientid\", \"date\"] + target_cols]\n",
    "generated_df_averaged_no_na[\"date\"] = pd.to_datetime(generated_df_averaged_no_na[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_forward_predictions_no_na = copy_forward_predictions.dropna(subset=target_cols, how=\"all\").copy()\n",
    "copy_forward_targets_no_na = copy_forward_targets.dropna(subset=target_cols, how=\"all\").copy()\n",
    "\n",
    "# Destandardize copy forward predictions, column by column\n",
    "copy_forward_predictions_no_na[\"CDRSB\"] = copy_forward_predictions_no_na[\"CDRSB\"] * std_CDRSB + mean_CDSSB\n",
    "copy_forward_predictions_no_na[\"ADAS11\"] = copy_forward_predictions_no_na[\"ADAS11\"] * std_ADAS11 + mean_ADAS11\n",
    "copy_forward_predictions_no_na[\"MMSE\"] = copy_forward_predictions_no_na[\"MMSE\"] * std_MMSE + mean_MMSE\n",
    "\n",
    "# Destandardize copy forward targets, column by column\n",
    "copy_forward_targets_no_na[\"CDRSB\"] = copy_forward_targets_no_na[\"CDRSB\"] * std_CDRSB + mean_CDSSB\n",
    "copy_forward_targets_no_na[\"ADAS11\"] = copy_forward_targets_no_na[\"ADAS11\"] * std_ADAS11 + mean_ADAS11\n",
    "copy_forward_targets_no_na[\"MMSE\"] = copy_forward_targets_no_na[\"MMSE\"] * std_MMSE + mean_MMSE\n",
    "\n",
    "# Destandardize lightgbm predictions, column by column\n",
    "lightgbm_predictions[\"CDRSB\"] = lightgbm_predictions[\"CDRSB\"] * std_CDRSB + mean_CDSSB\n",
    "lightgbm_predictions[\"ADAS11\"] = lightgbm_predictions[\"ADAS11\"] * std_ADAS11 + mean_ADAS11\n",
    "lightgbm_predictions[\"MMSE\"] = lightgbm_predictions[\"MMSE\"] * std_MMSE + mean_MMSE\n",
    "\n",
    "# Convert date to datetime\n",
    "copy_forward_predictions_no_na[\"date\"] = pd.to_datetime(copy_forward_predictions_no_na[\"date\"])\n",
    "copy_forward_targets_no_na[\"date\"] = pd.to_datetime(copy_forward_targets_no_na[\"date\"])\n",
    "lightgbm_predictions[\"date\"] = pd.to_datetime(lightgbm_predictions[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MAE\n",
    "mae_copy_forward = {}\n",
    "mae_generated = {}\n",
    "mae_lightgbm = {}\n",
    "\n",
    "for col in target_cols:\n",
    "    # Extract from target the non-na values, then merge on patientid and date\n",
    "    true_values = copy_forward_targets_no_na[[\"patientid\", \"date\", col]]\n",
    "    true_values_no_na = true_values.dropna(subset=[col], how=\"all\")\n",
    "\n",
    "    # Extract from predictions the non-na values, then merge on patientid and date\n",
    "    copy_forward_values = copy_forward_predictions_no_na[[\"patientid\", \"date\", col]]\n",
    "    copy_forward_non_na = copy_forward_values.dropna(subset=[col], how=\"all\")\n",
    "\n",
    "    # Get MAE for generated\n",
    "    generated_values = generated_df_averaged_no_na[[\"patientid\", \"date\", col]]\n",
    "    generated_non_na = generated_values.dropna(subset=[col], how=\"all\")\n",
    "\n",
    "    # Get lightGBM\n",
    "    lightgbm_values = lightgbm_predictions[[\"patientid\", \"date\", col]]\n",
    "    lightgbm_non_na = lightgbm_values.dropna(subset=[col], how=\"all\")\n",
    "\n",
    "    # Merge on patientid and date\n",
    "    merged_generated = pd.merge(true_values_no_na, generated_non_na, on=[\"patientid\", \"date\"], suffixes=(\"_true\", \"_generated\"))\n",
    "    merged_copy_forward = pd.merge(true_values_no_na, copy_forward_non_na, on=[\"patientid\", \"date\"], suffixes=(\"_true\", \"_copy_forward\"))\n",
    "    merged_lightgbm = pd.merge(true_values_no_na, lightgbm_non_na, on=[\"patientid\", \"date\"], suffixes=(\"_true\", \"_lightgbm\"))\n",
    "\n",
    "    mae_generated[col] = np.abs(merged_generated[col + \"_generated\"] - merged_generated[col + \"_true\"]).mean()\n",
    "    mae_copy_forward[col] = np.abs(merged_copy_forward[col + \"_copy_forward\"] - merged_copy_forward[col + \"_true\"]).mean()\n",
    "    mae_lightgbm[col] = np.abs(merged_lightgbm[col + \"_lightgbm\"] - merged_lightgbm[col + \"_true\"]).mean()\n",
    "\n",
    "    \n",
    "\n",
    "print(\"========== COPY FORWARD RESULTS ==========\")\n",
    "print(mae_copy_forward)\n",
    "\n",
    "print(\"========== LIGHTGBM RESULTS ==========\")\n",
    "print(mae_lightgbm)\n",
    "\n",
    "print(\"========== DT-GPT RESULTS ==========\")\n",
    "print(mae_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DT-GPT Outputs in common format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gpt_outputs = generated_df_averaged_no_na.copy()\n",
    "\n",
    "# Standardize\n",
    "dt_gpt_outputs[\"CDRSB\"] = (dt_gpt_outputs[\"CDRSB\"] - mean_CDSSB) / std_CDRSB\n",
    "dt_gpt_outputs[\"ADAS11\"] = (dt_gpt_outputs[\"ADAS11\"] - mean_ADAS11) / std_ADAS11\n",
    "dt_gpt_outputs[\"MMSE\"] = (dt_gpt_outputs[\"MMSE\"] - mean_MMSE) / std_MMSE\n",
    "\n",
    "# Add fake patient_sample_index\n",
    "dt_gpt_outputs[\"patient_sample_index\"] = \"split_0\"\n",
    "\n",
    "dt_gpt_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "dt_gpt_outputs.to_csv(\"./outputs/dt_gpt_outputs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc1_gpu_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
